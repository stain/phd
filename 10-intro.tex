Science is increasingly dependent on digital means, with researchers using computational methods for almost all aspects, ranging from digitising plant specimens in herbariums \cite{Thiers 2016}, to molecular simulations of protein bindings for pharmacetical drug design \cite{Sledz 2018}. 

Academics, government agencies and industry are now commonly making data publicly available under open licenses, feeding a broadening democratisation of science \cite{Kitchin 2021} across social-economic borders\footnote{Although open data practices do not necessarily benefit the Global South \cite{Serwadda 2018}}, and expanding the potential for new multidiciplinary fields, commercialisation, citizen engagement and wider societal benefits \cite{Bisol 2014}.

Cloud-based computational infrastructures for ``big data'' are readily available for use with a wide range of open source software, making research outputs accessible for further large scale secondary data analysis and detailed visualisations \cite{Hashem 2015}.

However, in this accelerated ecosystem of Open Science, concerns have been raised about replicability of research findings \cite{Ioannidis 2005}, flagged as a ``reproducibility crisis'' \cite{Baker 2016}. It is perhaps then ironic that the increased use of computers -- with their inherently repeatable execution mechanisms -- has negatively contributed to this crisis, as research publications do \emph{not} commonly provide sufficient computational details such as code, data downloads or software versions \cite{Stodden 2016}.

A recent increased focus on reusability of digital data and computational methods has seen the attention of funders and research communities. This led to the development of the \acrshort{FAIR} principles for making data and their metadata \acrlong{FAIR}, in order for them to be retrievable and understandable through programmatic use \cite{Wilkinson 2016}.

One technological measure for achieving FAIR is using \acrlong{LD}, a set of practices for publishing and relating data on the Web using controlled vocabularies, serialised using formats of the \acrfull{RDF}. 

Computational \glspl{Workflow} have been developed as ways to structure execution of software tools, for instance for scientific data analysis, so that, by using a \gls{WfMS}, tool execution is reproducible, scalable and documented. For this purpose, workflow systems have become heavily adopted by some research fields such as life sciences, however the workflows are not commonly shared as part of scholarly outputs.

\acrfull{RO} is a concept proposed for sharing composites of research artefacts, together with their history and related resources such as software, workflows and external references.
 
The FAIR principles are widely referenced in Open Science literature, and nominally adapted by many research data repositories, but how can they be translated into practice by typical researchers which may be using workflow systems, but not know any Linked Data technologies? 

This is the focus for this thesis, where I investigate \emph{Linked Data approaches to implementing FAIR Research Objects and sharing reproducible Computational Workflows}.

\subsection{What else?}

%%



How are people trying FAIR ? 

A major initiative for looking at implementing FAIR has been FDO.

FDO aims to provide concrete constraints for systems that lead to predictable machine actions / machine actionability.

Reference implemantations. --> RQ1

*Define machine actionability*

--> RQ1

There may be existing FDO implemantations, we look at Web stuff

%%

Then lead into RO-Crate

%% 

Going beyond data into methods and workflows.





\section{FAIR Principles}
\label{ch10:fair-principles}

The \acrshort{FAIR} Principles \cite{Wilkinson 2016} were introduced to improve sharing and digital reuse of research outputs ("\emph{data}") as part of emerging open research practices. The main goals of FAIR are to support \textbf{F}indability, \textbf{A}ccessability, \textbf{I}nteroperability and \textbf{R}eusability, through machine-readable metadata and standardised publication methods for data, as quoted in Table \vref{ch10:fair}.

\begin{table}[htp]
\small
\begin{tabular}{|r l|}
    \hline
    \multicolumn{2}{|l|}{In order to be \textbf{Findable}:} \\
    F1 & (Meta)data are assigned a globally unique and persistent \emph{identifier}. \\
    F2 & Data are described with rich \emph{metadata} (defined by R1 below). \\
    F3 & Metadata clearly and explicitly \emph{include the identifier} of the data it describes. \\
    F4 & (Meta)data are \emph{registered} or \emph{indexed} in a searchable resource. \\
    & \\
     \multicolumn{2}{|l|}{In order to be \textbf{Accessible}:} \\


    A1 & (Meta)data are \emph{retrievable} by their identifier using a 
        \emph{standardized} communications protocol. \\
    A1.1 & The protocol is \emph{open}, free, and universally implementable. \\
    A1.2 & The protocol allows for an \emph{authentication} and  
            \emph{authorization} procedure, where necessary. \\
     A2 & \emph{Metadata} are accessible, even when the \emph{data are no longer available}. \\

     & \\
     \multicolumn{2}{|l|}{In order to be \textbf{Interoperable}:} \\
     I1 & 
     (Meta)data use a \emph{formal}, accessible, shared, and 
         broadly applicable \emph{language for} \\
        &  \emph{knowledge representation}. \\
     I2 & (Meta)data use \emph{vocabularies} that follow FAIR principles. \\
     I3 & (Meta)data include qualified \emph{references} to other (meta)data.. \\

     & \\
     \multicolumn{2}{|l|}{In order to be \textbf{Reusable}:} \\
     R1 & Meta(data) are richly described with a plurality of 
         accurate and relevant \emph{attributes}. \\
            R1.1 & (Meta)data are released with a clear and accessible \emph{data usage license}. \\
            R1.2 & (Meta)data are associated with detailed \emph{provenance}. \\
            R1.3 & (Meta)data meet domain-relevant community \emph{standards}. \\
    \hline

\end{tabular}
\caption{FAIR Guiding Principles; adapted from \cite{Wilkinson 2016}, emphasis shown in \emph{italics}.}
\label{ch10:fair}
\end{table}

Although these guidelines are quite specific, they do not prescribe any particular technology or repository \cite{Mons 2017}. Further formalizations of the FAIR principles include RDA's FAIR Data Maturity Model \cite{FAIR Maturity 2020,Bahui 2020}. FAIR has also been expanded beyond data, e.g. to cover software \cite{Katz 2021b}, computational workflows \cite{Goble 2020}, training materials \cite{Garcia 2020a}, machine learning models \cite{Duarte 2023} and digital twins \cite{Schultes 2022}. 

The FAIR principles have become highly influential for open research stakeholders \cite{Jacobsen 2020}, particularly in large research infrastructure initatives such as by the European Open Science Cloud \footurl{https://eosc.eu/}{(EOSC)} \cite{Schouppe 2018}, and increasing awareness and support for the principles by national Open Science policies and funders \cite{Davidson 2019,Davidson 2022}.
Implementation of the principles by platform developers and researchers have however raised many questions and practical challenges \cite{Mons 2020,Riungu-Kalliosaari 2022}. 

For instance, in order to evaluate a given resource's \emph{FAIRness}, additional technical constraints need to be assumed, such as use of particular formal vocabularies. \emph{FAIR metrics} \cite{Wilkinson 2018,Devaraju 2021} have recently become an area of active research, as different FAIR assessment tools may give a range of results for the same data resource, primarily based on which technical assumptions are made \cite{Wilkinson 2022a,Verburg 2023}.

Recently there have been increased emphasis on training and awareness on the FAIR principles \cite{Shanahan 2021,Rocca-Serra 2023}, and registries of standards and vocabularies \cite{Sansone 2019}.
However---with a general lack of skills in data management planning, inadequate (opaque) data formats and lack of time investment to provide rich metadata---data, even when shared through repositories, often becomes effectively "un-findable" or near impossible to reuse \cite{Carballo-Garcia 2022}.

From this we can identify challenges with regards to finding practical ways for research software developers to generate and consume FAIR data.


\section{Achieving FAIR}

.. Existing


\subsection{Existing approaches to implementing FAIR}

GO-FAIR etc. 
FIP

Linked Data go here


The vision on the Semantic Web \cite{Berners-Lee 1999} were proposed as a way to make structured data on the Web. This evolved into a \acrfull{LD} stack that uses logic-based ontologies, Web deployment of individually described resources, and cross-references between these resources with \acrfull{URI} identifiers. The Semantic Web then is the ecosystem of such \acrlong{LD} resources, which can be queried, traversed and reasoned about. 

..


\subsection{FAIR Digital Objects (FDO)}

\emph{FAIR Digital Object} (\acrshort{FDO}) has been proposed as a machine-actionable ecosystem of scholarly outputs \cite{Schultes 2019}, in theory realising the \acrshort{FAIR} principles 
%\cite{Wilkinson 2016}
for a programmable mesh of strongly typed objects, which goes beyond the open data publication practices that the FAIR guidelines have popularised.

The FDO guidelines\footnote{Section \vref{ch3:fdo-requirements}} \cite{Anders 2023} and the more detailed FDO specifications \cite{Ivonne 2023} are largely conceptual in nature, with several demonstrated implementations \cite{Wittenburg 2022a,Lannom 2022a} which in theory can operate side-by-side. Many of these rely on network protocols \cite{Reilly 2009,Sun 2003a} which are not particularly familiar to software developers, and not commonly supported by software libraries or frameworks.

This divergence, while sound from a technical perspective, raises organisational challenges for wider adoption of FDOs, e.g. within EOSC and research infrastructures, and might be introducing a steeper learning curve than already exists for FAIR.



\subsection{Research Objects}

Importance of processes to FAIR. Reproducibility. 

\acrfullpl{RO}
\cite{Bechhofer 2013} have been proposed as a mechanism to capture a range of diverse scholarly outputs in a single archivable item with detailed metadata. The RO concept was first realised using Semantic Web ontologies \cite{myExperiment 2009,Belhajjame 2015} -- these approaches primarily targetted long-term preservation of \glspl{scientific workflow}, utillised by RO as a mechanism to capture computational methods.

The principles of Research Objects extend far beyond workflows; however, early RO implementations mainly focused on capturing software \cite{Goble 2018}. To some extent the lack of wider adoption of ontology-based ROs can also be explained by developers of researcher-facing software and platforms (e.g. repositories, data management systems) having a lack of familiarity with use of Semantic Web technology -- or worse, they tried and then struggled \cite{Carriero 2010,Tudorache 2020}.

From this, a challenge is to make Linked Data technology approachable for developers who are best placed at implementing the FAIR principles, in platforms that are effectively making Research Objects.




\subsection{Computational Workflows}

A growing (if not majority) part of scientific analysis is now conducted using software and computational models. The concept of \emph{Research Software Engineering} \cite{Cohen 2020} has been established along with new professions \emph{Research Software Engineer} \cite{Baxter 2012} and \emph{Data Scientist} \cite{van der Aalst 2014} -- researchers are not just using off-the-shelf software, but also combining computational tools (e.g. pipelines) and writing their own analytical source code (e.g. R scripts) and simulations.

From this observation emerges the need to treat software as FAIR artefacts \cite{Lamprecht 2019}, following best practices for documentation \cite{Lee 2018}, open development \cite{Prlić 2012} and ensuring research software is robust \cite{Taschuk 2017} so it can be reused and cited as scholarly outputs \cite{Smith 2016}. 
With this motivation the principles of FAIR Research Software \cite{Katz 2021b} have been established by the RDA FAIR for Research Software (FAIR4RS) Working Group \cite{Barker 2022} and are gradually building traction, particularly in the life sciences. A remaining challenge is how citations of research software can be practically propagated following their execution. 

While sharing of research software helps distribute the computational methods, the \emph{way} software is used for a particular analysis requires additional measures to make it \emph{reproducible} \cite{Stodden 2016,Sandve 2013}.

\emph{Computational Workflows} (or \glspl{scientific workflow}) are used to structure and automate data analysis pipelines so they can be scalable, portable and explainable \cite{Atkinson 2017}, and as a side-effect of these features can significantly improve reproducibility \cite{Cohen-Boulakia 2017}. 

Several challenges emerge when considering sharing of workflows as FAIR digital objects. For instance, a workflow composes multiple tools that themselves need to be shared. Data used by a workflow have their own attribution and licenses. The execution of a workflow produces many intermediate data, but understanding that data creation requires deep knowledge about the particular \acrfull{WfMS}.





\section{Research Outline and Questions}
\label{intro:outline}

Following the above motivation, this section elaborates Research Questions (RQ) on three interlinked ideas:

\begin{enumerate}
    \item Realization of the FAIR Digital Object concept using Web technologies.
    \item Implementing FAIR Research Objects with an pragmatic use of Linked Data practices.
    \item Unifying a FAIR Digital Object approach for computational workflows
\end{enumerate}


\subsection{Aims for FAIR Digital Objects on the Web (RQ1)}
\label{intro:rq1}

The Web is ubiquitous in modern software engineering \cite{Taivalsaari 2021}, used for everything from user interfaces, mobile applications and controlling devices to enterprise cross-platform integrations, backend data processing and microservices, frequently utilising cloud computing which itself is controlled using Web technologies \cite{Marinescu 2023}.

The goals of \acrfullpl{FDO} seem to have an overlap with the motivations for the Semantic Web and Linked Data, and it is not clear if a different set of network protocols are required for FDO.

A relevant research question therefore is: 

\paragraph{RQ1:}\label{rq1} 
Can the the promising FDO concept be realised using existing Web technology, taking into account the lessons learnt from the early Semantic Web developments and more recent Linked Data practices?

I address RQ1 in Chapters \ref{chapter:background} and \ref{chapter:fdo}.


\subsection{Aims for FAIR Research Objects (RQ2)}
\label{intro:rq2}

Following the lessons learnt on early \acrfull{RO} implementations and the emerging \acrshort{FAIR} principles, a new engagement between the RO and digital libraries communities started in 2018, where it was agreed to formulate a lightweight approach to Research Objects \cite{Sefton 2018,Ó Carragáin 2019b} for the purpose of data packaging. The updated aims of \emph{FAIR Research Objects} can be summarised as:
 
\begin{itemize}
    \item Describe and package data collections, datasets, software etc. with their metadata.
    \item Platform-independent object exchange between repositories and services.
    \item Support reproducibility and analysis: link data with codes and workflows.
    \item Transfer of sensitive/large distributed datasets with persistent identifiers.
    \item Aggregate citations and persistent identifiers.
    \item Propagate provenance and existing metadata.
    \item Publish and archive mixed objects and references.
    \item Reuse existing standards, but hide their complexity.
\end{itemize}

Following from these aims, the second research question is: 

\paragraph{RQ2:}\label{rq2}  Can a more pragmatic use of Linked Data practices better implement Research Objects for a wider developer audience, by using familiar Web technologies and give lightweight recommendations?

RQ2 is primarily addressed by Chapter \ref{chapter:ro-crate}.


\subsection{Aims for FAIR Computational Workflows (RQ3)}
\label{intro:rq3}

There exists a plethora of \gls{workflow} systems and languages \cite{Leipzig 2021,Amstutz 2021}, although some recent efforts have created the Common Workflow Language \cite{Crusoe 2022} as a standard representation with \footurl{https://www.commonwl.org/user_guide/topics/metadata-and-authorship.html}{FAIR metadata capabilities} that is executable by multiple engines. 

Notably, workflow definitions themselves can be considered FAIR scholarly outputs \cite{Goble 2020} -- \emph{FAIR Computational Workflows} which are published in repositories including Dockstore \cite{Yuen 2021} and WorkflowHub \cite{Goble 2021}.
One could consider computational workflows as a kind of FAIR Research Software \cite{de Visser 2023}, but by their nature workflows also \emph{encourage the FAIR principles} (e.g. preparing a computational tool for a workflow system \cite{Brack 2022a} may include publishing it in a container registry). Workflow systems are also useful for creating and consuming FAIR Digital Objects \cite{Wittenburg 2022b}, and in addition workflow systems commonly provide explicit provenance logs of their executions.

Approaches to describing workflow provenance in a machine-readable format were initially diverse \cite{Cruz 2009}, and later converged on the use of ontologies \cite{Missier 2010}, most notably using W3C PROV-O \cite{Lebo 2013a} but with various specializations \cite{Garijo 2011,Garijo 2012,Missier 2013,Belhajjame 2015,Cuevas-Vicenttín 2016}. 

The tendency for workflow provenance models to diverge may be down to differences in the execution semantics of different workflow systems -- which if accurately reflected in provenance means further differences at this level. This in turn leads to incompatibility of provenance traces and lack of common tooling. In addition execution details may obscure the link from the computational procesesses and the final workflow data outputs that researchers ultimately care more about than the intricacies of the workflow engine.

The third research question from these considerations is therefore: 

\paragraph{RQ3:} \label{rq3} Can a FAIR Digital Object approach for computational workflows unify machine-readable descriptions of research software, data and provenance, which can be consistently implemented by developers of different workflow management systems?

The multiple aspects of RQ3, as highlighted in this section, are adressed by Chapter \ref{chapter:workflows}.


\section{Main Contributions}
\label{intro:contributions}

The contributions from this PhD include:

\begin{itemize}
    \item An evaluation of FAIR Digital Objects and Linked Data, considering them from a developer perspective as distributed object systems.
    \item A Research Object implementation based on familiar Web technologies, adapted and extended by numerous research projects and software developers.
    \item A profile to capture provenance of computational workflow runs using this implementation, implemented by at least six workflow management systems.
\end{itemize}

These contributions have not evolved in isolation, but in co-development with multiple international collaborations (see appendix \vref{ch11:acknowledgements}).


\section{Thesis Overview}
\label{intro:overview}

Chapter \vref{chapter:background} gives the background of the concepts \emph{FAIR Digital Object} (FDO) and \emph{Linked Data}, including a brief history of the \emph{Semantic Web}, followed by a critical analysis of these technologies and their use. 

Chapter \vref{chapter:fdo} targets RQ1 and contributes a framework-based evaluation of Linked Data and FDO as possible architectures for implementing a distributed object system for the purpose of FAIR data publishing. The discussion in this chapter considers how the two approaches can benefit from each other's strengths. 

Chapter \vref{chapter:ro-crate} addresses RQ2 by introducing the contribution of \emph{RO-Crate} -- a pragmatic data packaging mechanism using Linked Data standards to implement FDO and be extensible for domain-specific metadata.  

Chapter \vref{chapter:workflows} considers RQ3 by exploring the relationship between Computational Workflows and FAIR practices using RO-Crate and FDO, with use cases from molecular dynamics and specimen digitization. The contribution of the \emph{Workflow Run Crate profiles} is presented as an interoperable way to capture and publish workflow execution provenance. 

Chapter \vref{chapter:conclusions} summarises and discusses the contributions from this thesis, reflects on later third-party developments and concludes by evaluating the research questions.


\section{Origins}
\label{intro:origins}

Chapter \ref{ch3:background} and Section \ref{ch3:evaluating-fdo-ld} are based on the journal article \emph{Evaluating FAIR Digital Object and Linked Data as distributed object systems} \cite{Soiland-Reyes 2024b}  (see appendices \ref{ch11:fdo} and \ref{ch10:fdo}). I am the main author of this manuscript.

Section \ref{ch2:updating-linked-data-practices-for-fair-digital-object-principles} is based on \emph{Updating Linked Data practices for FAIR Digital Object principles} \cite{Soiland-Reyes 2022d} (see appendices \ref{ch11:updating-ld} and \ref{ch10:updating-ld}). I am the main author of this manuscript.

Sections \ref{ch5:packaging-research-artefacts-with-ro-crate} and \ref{ch5:formaldefinition} are based on the publication \emph{Packaging research artefacts with RO-Crate} \cite{Soiland-Reyes 2022a} (see appendices \ref{ch11:packagingrocrate}, \ref{ch10:packagingrocrate} and \ref{ch10:formalizing}). I am the main author of this manuscript.

Section \ref{ch4:lightweight-fdo} is based on the publication \emph{Creating lightweight FAIR digital objects with RO-Crate} \cite{Soiland-Reyes 2022c} (see appendices \ref{ch11:lightweight} and \ref{ch10:lightweight}). I am the main author of this manuscript.

Section \ref{ch6:making-canonical-workflow-building-blocks-interoperable-across-workflow-languages} is based on the publication \emph{Making Canonical Workflow Building Blocks interoperable across workflow languages} \cite{Soiland-Reyes 2022b} (see appendices \ref{ch11:canonical} and \ref{ch10:canonical}). I am the main author of this manuscript.

Section \ref{ch8:the-specimen-data-refinery} is based on the publication \emph{The Specimen Data Refinery: A
canonical workflow framework and FAIR Digital Object approach to speeding up digital mobilisation of natural history collections} \cite{Hardisty 2022} (see appendices \ref{ch11:refinery} and \ref{ch10:refinery}). I mainly contributed to Sections \ref{ch8:workflow-management-systems-and-canonical-workflows-for-research}, \ref{ch8:fair-packaging-of-researchworkflow-objects-with-ro-crate}, \ref{ch8:fdo-types}, \ref{ch8:discussion} in this manuscript.

Section \ref{ch7:incrementally-building-fair-digital-objects-with-specimen-data-refinery-workflows} is based on the publication \emph{Incrementally building FAIR Digital Objects with Specimen Data
Refinery workflows} \cite{Woolland 2022} (see appendices \ref{ch11:incrementally-fdo} and \ref{ch10:incrementally-fdo}). I am the main author of this manuscript.

Section \ref{ch54:wrroc} is based on the publication \emph{
Recording provenance of workflow runs with RO-Crate} \cite{Leo 2023b} (see appendices \ref{ch11:wrroc} and \ref{ch10:wrroc}). I am the last author of this manuscript, and have mainly contributed to Sections \ref{ch54:introduction}, \ref{ch54:discussion}, \ref{ch54:trusted-workflow-run-crate}, \ref{ch54:bco-crate}.
